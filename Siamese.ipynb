{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saira\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing required library\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "(250, 200, 500)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the image data\n",
    "file_dir1 = 'input1/*'\n",
    "file_dir2 = 'input2/*'\n",
    "files = glob.glob(file_dir1)\n",
    "print(len(files))\n",
    "x1 = []\n",
    "for f1 in files:\n",
    "      img_dir = os.path.join(f1)\n",
    "  #print('img_dir',img_dir)\n",
    "      images = glob.glob(img_dir)\n",
    "      for img in images:\n",
    "        img_temp = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "        img_temp = cv2.resize(img_temp,(500,200))\n",
    "        img_temo = img_temp/255\n",
    "        x1.append(img_temp)\n",
    "import numpy as np\n",
    "x1 = np.array(x1)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_dir input2\\000.jpg\n",
      "img_dir input2\\001.jpg\n",
      "img_dir input2\\002.jpg\n",
      "img_dir input2\\003.jpg\n",
      "img_dir input2\\004.jpg\n",
      "img_dir input2\\005.jpg\n",
      "img_dir input2\\006.jpg\n",
      "img_dir input2\\007.jpg\n",
      "img_dir input2\\008.jpg\n",
      "img_dir input2\\009.jpg\n",
      "img_dir input2\\010.jpg\n",
      "img_dir input2\\011.jpg\n",
      "img_dir input2\\012.jpg\n",
      "img_dir input2\\013.jpg\n",
      "img_dir input2\\014.jpg\n",
      "img_dir input2\\015.jpg\n",
      "img_dir input2\\016.jpg\n",
      "img_dir input2\\017.jpg\n",
      "img_dir input2\\018.jpg\n",
      "img_dir input2\\019.jpg\n",
      "img_dir input2\\020.jpg\n",
      "img_dir input2\\021.jpg\n",
      "img_dir input2\\022.jpg\n",
      "img_dir input2\\023.jpg\n",
      "img_dir input2\\024.jpg\n",
      "img_dir input2\\025.jpg\n",
      "img_dir input2\\026.jpg\n",
      "img_dir input2\\027.jpg\n",
      "img_dir input2\\028.jpg\n",
      "img_dir input2\\029.jpg\n",
      "img_dir input2\\030.PNG\n",
      "img_dir input2\\031.PNG\n",
      "img_dir input2\\032.PNG\n",
      "img_dir input2\\033.PNG\n",
      "img_dir input2\\034.PNG\n",
      "img_dir input2\\035.PNG\n",
      "img_dir input2\\036.PNG\n",
      "img_dir input2\\037.PNG\n",
      "img_dir input2\\038.PNG\n",
      "img_dir input2\\039.PNG\n",
      "img_dir input2\\040.PNG\n",
      "img_dir input2\\041.PNG\n",
      "img_dir input2\\042.PNG\n",
      "img_dir input2\\043.PNG\n",
      "img_dir input2\\044.PNG\n",
      "img_dir input2\\045.PNG\n",
      "img_dir input2\\046.PNG\n",
      "img_dir input2\\047.PNG\n",
      "img_dir input2\\048.PNG\n",
      "img_dir input2\\049.PNG\n",
      "img_dir input2\\050.PNG\n",
      "img_dir input2\\051.PNG\n",
      "img_dir input2\\052.PNG\n",
      "img_dir input2\\053.PNG\n",
      "img_dir input2\\054.PNG\n",
      "img_dir input2\\055.PNG\n",
      "img_dir input2\\056.PNG\n",
      "img_dir input2\\057.PNG\n",
      "img_dir input2\\058.PNG\n",
      "img_dir input2\\059.PNG\n",
      "img_dir input2\\060.PNG\n",
      "img_dir input2\\061.png\n",
      "img_dir input2\\062.PNG\n",
      "img_dir input2\\063.PNG\n",
      "img_dir input2\\064.PNG\n",
      "img_dir input2\\065.PNG\n",
      "img_dir input2\\066.PNG\n",
      "img_dir input2\\067.PNG\n",
      "img_dir input2\\068.png\n",
      "img_dir input2\\069.PNG\n",
      "img_dir input2\\070.PNG\n",
      "img_dir input2\\071.PNG\n",
      "img_dir input2\\072.PNG\n",
      "img_dir input2\\073.PNG\n",
      "img_dir input2\\074.PNG\n",
      "img_dir input2\\075.png\n",
      "img_dir input2\\076.PNG\n",
      "img_dir input2\\077.PNG\n",
      "img_dir input2\\078.PNG\n",
      "img_dir input2\\079.PNG\n",
      "img_dir input2\\080.PNG\n",
      "img_dir input2\\081.PNG\n",
      "img_dir input2\\082.png\n",
      "img_dir input2\\083.PNG\n",
      "img_dir input2\\084.PNG\n",
      "img_dir input2\\085.PNG\n",
      "img_dir input2\\086.png\n",
      "img_dir input2\\087.png\n",
      "img_dir input2\\088.png\n",
      "img_dir input2\\089.png\n",
      "img_dir input2\\090.PNG\n",
      "img_dir input2\\091.PNG\n",
      "img_dir input2\\092.PNG\n",
      "img_dir input2\\093.png\n",
      "img_dir input2\\094.PNG\n",
      "img_dir input2\\095.PNG\n",
      "img_dir input2\\096.PNG\n",
      "img_dir input2\\097.PNG\n",
      "img_dir input2\\098.PNG\n",
      "img_dir input2\\099.PNG\n",
      "img_dir input2\\100.png\n",
      "img_dir input2\\101.png\n",
      "img_dir input2\\102.PNG\n",
      "img_dir input2\\103.PNG\n",
      "img_dir input2\\104.PNG\n",
      "img_dir input2\\105.PNG\n",
      "img_dir input2\\106.PNG\n",
      "img_dir input2\\107.png\n",
      "img_dir input2\\108.png\n",
      "img_dir input2\\109.png\n",
      "img_dir input2\\110.png\n",
      "img_dir input2\\111.png\n",
      "img_dir input2\\112.png\n",
      "img_dir input2\\113.png\n",
      "img_dir input2\\114.png\n",
      "img_dir input2\\115.png\n",
      "img_dir input2\\116.png\n",
      "img_dir input2\\117.PNG\n",
      "img_dir input2\\118.png\n",
      "img_dir input2\\119.png\n",
      "img_dir input2\\120.png\n",
      "img_dir input2\\121.png\n",
      "img_dir input2\\122.png\n",
      "img_dir input2\\123.png\n",
      "img_dir input2\\124.png\n",
      "img_dir input2\\125.png\n",
      "img_dir input2\\126.png\n",
      "img_dir input2\\127.png\n",
      "img_dir input2\\128.png\n",
      "img_dir input2\\129.png\n",
      "img_dir input2\\130.png\n",
      "img_dir input2\\131.png\n",
      "img_dir input2\\132.png\n",
      "img_dir input2\\133.png\n",
      "img_dir input2\\134.png\n",
      "img_dir input2\\135.png\n",
      "img_dir input2\\136.png\n",
      "img_dir input2\\137.png\n",
      "img_dir input2\\138.png\n",
      "img_dir input2\\139.png\n",
      "img_dir input2\\140.png\n",
      "img_dir input2\\141.png\n",
      "img_dir input2\\142.png\n",
      "img_dir input2\\143.png\n",
      "img_dir input2\\144.png\n",
      "img_dir input2\\145.png\n",
      "img_dir input2\\146.png\n",
      "img_dir input2\\147.png\n",
      "img_dir input2\\148.png\n",
      "img_dir input2\\149.png\n",
      "img_dir input2\\150.png\n",
      "img_dir input2\\151.png\n",
      "img_dir input2\\152.png\n",
      "img_dir input2\\153.png\n",
      "img_dir input2\\154.png\n",
      "img_dir input2\\155.png\n",
      "img_dir input2\\156.png\n",
      "img_dir input2\\157.png\n",
      "img_dir input2\\158.png\n",
      "img_dir input2\\159.png\n",
      "img_dir input2\\160.png\n",
      "img_dir input2\\161.png\n",
      "img_dir input2\\162.png\n",
      "img_dir input2\\163.png\n",
      "img_dir input2\\164.png\n",
      "img_dir input2\\165.png\n",
      "img_dir input2\\166.png\n",
      "img_dir input2\\167.png\n",
      "img_dir input2\\168.png\n",
      "img_dir input2\\169.png\n",
      "img_dir input2\\170.png\n",
      "img_dir input2\\171.png\n",
      "img_dir input2\\172.png\n",
      "img_dir input2\\173.png\n",
      "img_dir input2\\174.png\n",
      "img_dir input2\\175.png\n",
      "img_dir input2\\176.png\n",
      "img_dir input2\\177.png\n",
      "img_dir input2\\178.png\n",
      "img_dir input2\\179.png\n",
      "img_dir input2\\180.png\n",
      "img_dir input2\\181.png\n",
      "img_dir input2\\182.png\n",
      "img_dir input2\\183.png\n",
      "img_dir input2\\184.png\n",
      "img_dir input2\\185.png\n",
      "img_dir input2\\186.png\n",
      "img_dir input2\\187.png\n",
      "img_dir input2\\188.png\n",
      "img_dir input2\\189.png\n",
      "img_dir input2\\190.png\n",
      "img_dir input2\\191.png\n",
      "img_dir input2\\192.png\n",
      "img_dir input2\\193.png\n",
      "img_dir input2\\194.png\n",
      "img_dir input2\\195.png\n",
      "img_dir input2\\196.png\n",
      "img_dir input2\\197.png\n",
      "img_dir input2\\198.png\n",
      "img_dir input2\\199.png\n",
      "img_dir input2\\200.png\n",
      "img_dir input2\\201.png\n",
      "img_dir input2\\202.png\n",
      "img_dir input2\\203.png\n",
      "img_dir input2\\204.png\n",
      "img_dir input2\\205.png\n",
      "img_dir input2\\206.png\n",
      "img_dir input2\\207.png\n",
      "img_dir input2\\208.png\n",
      "img_dir input2\\209.png\n",
      "img_dir input2\\210.png\n",
      "img_dir input2\\211.png\n",
      "img_dir input2\\212.png\n",
      "img_dir input2\\213.png\n",
      "img_dir input2\\214.PNG\n",
      "img_dir input2\\215.png\n",
      "img_dir input2\\216.png\n",
      "img_dir input2\\217.png\n",
      "img_dir input2\\218.png\n",
      "img_dir input2\\219.png\n",
      "img_dir input2\\220.png\n",
      "img_dir input2\\221.png\n",
      "img_dir input2\\222.png\n",
      "img_dir input2\\223.png\n",
      "img_dir input2\\224.png\n",
      "img_dir input2\\225.png\n",
      "img_dir input2\\226.png\n",
      "img_dir input2\\227.png\n",
      "img_dir input2\\228.png\n",
      "img_dir input2\\229.png\n",
      "img_dir input2\\230.png\n",
      "img_dir input2\\231.png\n",
      "img_dir input2\\232.png\n",
      "img_dir input2\\233.png\n",
      "img_dir input2\\234.PNG\n",
      "img_dir input2\\235.png\n",
      "img_dir input2\\236.png\n",
      "img_dir input2\\237.png\n",
      "img_dir input2\\238.png\n",
      "img_dir input2\\239.png\n",
      "img_dir input2\\240.PNG\n",
      "img_dir input2\\241.PNG\n",
      "img_dir input2\\242.PNG\n",
      "img_dir input2\\243.PNG\n",
      "img_dir input2\\244.PNG\n",
      "img_dir input2\\245.png\n",
      "img_dir input2\\246.png\n",
      "img_dir input2\\247.png\n",
      "img_dir input2\\248.png\n",
      "img_dir input2\\249.png\n",
      "(250, 200, 500)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "files = glob.glob(file_dir2)\n",
    "x2 = []\n",
    "for f1 in files:\n",
    "  img_dir = os.path.join(f1)\n",
    "  print('img_dir',img_dir)\n",
    "  images = glob.glob(img_dir)\n",
    "  \n",
    "  for img in images:\n",
    "    img_temp = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "    img_temp = cv2.resize(img_temp,(500,200))\n",
    "    img_temo = img_temp/255\n",
    "    x2.append(img_temp)\n",
    "import numpy as np\n",
    "x2 = np.array(x2)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel = 'ylabel.csv'\n",
    "y = pd.read_csv(ylabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x1,x2,y = shuffle(x1,x2,y,random_state=2)\n",
    "\n",
    "# splitting dataset into train test\n",
    "x1_train = x1[0:180]\n",
    "x1_train = x1_train.reshape(180,200,500,1)\n",
    "x1_val = x1[180:210]\n",
    "x1_val = x1_val.reshape(30,200,500,1)\n",
    "\n",
    "x2_train = x2[0:180]\n",
    "x2_train = x2_train.reshape(180,200,500,1)\n",
    "x2_val = x2[180:210]\n",
    "x2_val = x2_val.reshape(30,200,500,1)\n",
    "\n",
    "x1_test = x1[210 :]\n",
    "x1_test = x1_test.reshape(40,200,500,1)\n",
    "x2_test = x2[210 :]\n",
    "x2_test = x2_test.reshape(40,200,500,1)\n",
    "\n",
    "y_train = y[0:180]\n",
    "y_val = y[180:210]\n",
    "y_test = y[210 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    #input_shape = (200,500,1)\n",
    "    left_input=Input(input_shape)\n",
    "    right_input=Input(input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(10,10), activation='relu', input_shape=input_shape,\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64,(7,7), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D())   \n",
    "    model.add(Conv2D(64,(4,4), activation='relu', \n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128,(4,4), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='sigmoid',kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    \n",
    "    encoded_l=model(left_input)\n",
    "    encoded_r=model(right_input)\n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0]-tensors[1]))\n",
    "    L1_distance=L1_layer([encoded_l,encoded_r])\n",
    "    \n",
    "    prediction=Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    siamese_net1 = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    return siamese_net1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training process\n",
      "...............................\n",
      "Train on 180 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 645s 4s/step - loss: 12.0537 - accuracy: 0.5889 - val_loss: 5.5547 - val_accuracy: 0.5333\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 591s 3s/step - loss: 3.8424 - accuracy: 0.5500 - val_loss: 3.1274 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 505s 3s/step - loss: 2.7140 - accuracy: 0.5500 - val_loss: 2.3995 - val_accuracy: 0.4667\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 485s 3s/step - loss: 2.4141 - accuracy: 0.6056 - val_loss: 2.2774 - val_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 517s 3s/step - loss: 2.1329 - accuracy: 0.6722 - val_loss: 1.9940 - val_accuracy: 0.5333\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 506s 3s/step - loss: 1.9050 - accuracy: 0.6833 - val_loss: 1.9234 - val_accuracy: 0.6000\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 566s 3s/step - loss: 1.6140 - accuracy: 0.6944 - val_loss: 1.5254 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 509s 3s/step - loss: 1.4235 - accuracy: 0.7444 - val_loss: 1.5976 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 519s 3s/step - loss: 1.5997 - accuracy: 0.8056 - val_loss: 1.7363 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "155/180 [========================>.....] - ETA: 1:04 - loss: 1.5082 - accuracy: 0.8581"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((200,500,1))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(\"starting training process\")\n",
    "print(\"...............................\")\n",
    "#t_start = time.time()\n",
    "model.fit([x1_train,x2_train],y_train,verbose=1,batch_size=5,validation_data=[[x1_val,x2_val],y_val],epochs =20,shuffle = True)\n",
    "scores = model.evaluate([x1_test,x2_test],y_test,verbose=1)\n",
    "print(scores)\n",
    "model.save('siamese_net.h5')\n",
    "#t_stop = (time.time()-t_start())\n",
    "#print(t_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
